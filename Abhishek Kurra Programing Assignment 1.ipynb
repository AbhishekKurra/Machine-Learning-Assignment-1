{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMj25sFaKNKdbv83jydKf46",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbhishekKurra/Machine-Learning-Assignment-1/blob/main/Abhishek%20Kurra%20Programing%20Assignment%201.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKWM6HpqVaB1",
        "outputId": "1dd3fa9c-45af-4506-f92c-bf90313fca8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Hayes-Roth dataset...\n",
            "Hayes-Roth - Our KNN: 0.4247, Sklearn KNN: 0.3934\n",
            "T-statistic: 1.1056, P-value: 0.2976\n",
            "==================================================\n",
            "Processing Car Evaluation dataset...\n",
            "Car Evaluation - Our KNN: 0.9259, Sklearn KNN: 0.8663\n",
            "T-statistic: 5.9304, P-value: 0.0002\n",
            "==================================================\n",
            "Processing Breast Cancer dataset...\n",
            "Breast Cancer - Our KNN: 1.0000, Sklearn KNN: 1.0000\n",
            "T-statistic: nan, P-value: nan\n",
            "==================================================\n",
            "Testing enhanced KNN on Hayes-Roth dataset...\n",
            "Config: {'k': 3, 'distance_metric': 'euclidean', 'weights': 'uniform', 'kernel': None} -> Accuracy: 0.4319\n",
            "Config: {'k': 5, 'distance_metric': 'manhattan', 'weights': 'distance', 'kernel': None} -> Accuracy: 0.4390\n",
            "Config: {'k': 7, 'distance_metric': 'minkowski', 'weights': 'distance', 'kernel': 'gaussian'} -> Accuracy: 0.3929\n",
            "Config: {'k': 5, 'distance_metric': 'euclidean', 'weights': 'distance', 'kernel': 'epanechnikov'} -> Accuracy: 0.3863\n",
            "==================================================\n",
            "Testing enhanced KNN on Car Evaluation dataset...\n",
            "Config: {'k': 3, 'distance_metric': 'euclidean', 'weights': 'uniform', 'kernel': None} -> Accuracy: 0.8617\n",
            "Config: {'k': 5, 'distance_metric': 'manhattan', 'weights': 'distance', 'kernel': None} -> Accuracy: 0.9092\n",
            "Config: {'k': 7, 'distance_metric': 'minkowski', 'weights': 'distance', 'kernel': 'gaussian'} -> Accuracy: 0.9369\n",
            "Config: {'k': 5, 'distance_metric': 'euclidean', 'weights': 'distance', 'kernel': 'epanechnikov'} -> Accuracy: 0.7928\n",
            "==================================================\n",
            "Testing enhanced KNN on Breast Cancer dataset...\n",
            "Config: {'k': 3, 'distance_metric': 'euclidean', 'weights': 'uniform', 'kernel': None} -> Accuracy: 1.0000\n",
            "Config: {'k': 5, 'distance_metric': 'manhattan', 'weights': 'distance', 'kernel': None} -> Accuracy: 1.0000\n",
            "Config: {'k': 7, 'distance_metric': 'minkowski', 'weights': 'distance', 'kernel': 'gaussian'} -> Accuracy: 1.0000\n",
            "Config: {'k': 5, 'distance_metric': 'euclidean', 'weights': 'distance', 'kernel': 'epanechnikov'} -> Accuracy: 1.0000\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from scipy import stats\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "import warnings\n",
        "import requests\n",
        "import os\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class KNN:\n",
        "    def __init__(self, k=3, distance_metric='euclidean', weights='uniform', kernel=None):\n",
        "        self.k = k\n",
        "        self.distance_metric = distance_metric\n",
        "        self.weights = weights\n",
        "        self.kernel = kernel\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.X_train = X\n",
        "        self.y_train = y\n",
        "\n",
        "    def predict(self, X):\n",
        "        predictions = [self._predict(x) for x in X]\n",
        "        return np.array(predictions)\n",
        "\n",
        "    def _predict(self, x):\n",
        "\n",
        "        if self.distance_metric == 'euclidean':\n",
        "            distances = [self._euclidean_distance(x, x_train) for x_train in self.X_train]\n",
        "        elif self.distance_metric == 'manhattan':\n",
        "            distances = [self._manhattan_distance(x, x_train) for x_train in self.X_train]\n",
        "        elif self.distance_metric == 'minkowski':\n",
        "            distances = [self._minkowski_distance(x, x_train, 3) for x_train in self.X_train]\n",
        "        else:\n",
        "            raise ValueError(\"Distance metric not supported\")\n",
        "\n",
        "\n",
        "        k_indices = np.argsort(distances)[:self.k]\n",
        "        k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
        "        k_distances = [distances[i] for i in k_indices]\n",
        "\n",
        "\n",
        "        if self.weights == 'uniform':\n",
        "            most_common = Counter(k_nearest_labels).most_common(1)\n",
        "            return most_common[0][0]\n",
        "        else:\n",
        "            if self.weights != 'distance':\n",
        "                raise ValueError(\"Weighting method not supported\")\n",
        "\n",
        "\n",
        "\n",
        "            k_weights = [1/(d + 1e-10) for d in k_distances]\n",
        "\n",
        "\n",
        "            if self.kernel == 'gaussian':\n",
        "                k_weights = [np.exp(-d**2) for d in k_distances]\n",
        "            elif self.kernel == 'epanechnikov':\n",
        "                k_weights = [max(0, 1 - d**2) for d in k_distances]\n",
        "\n",
        "\n",
        "            weighted_votes = {}\n",
        "            for i, label in enumerate(k_nearest_labels):\n",
        "                if label not in weighted_votes:\n",
        "                    weighted_votes[label] = 0\n",
        "                weighted_votes[label] += k_weights[i]\n",
        "\n",
        "            return max(weighted_votes.items(), key=lambda x: x[1])[0]\n",
        "\n",
        "    def _euclidean_distance(self, x1, x2):\n",
        "        return np.sqrt(np.sum((x1 - x2)**2))\n",
        "\n",
        "    def _manhattan_distance(self, x1, x2):\n",
        "        return np.sum(np.abs(x1 - x2))\n",
        "\n",
        "    def _minkowski_distance(self, x1, x2, p):\n",
        "        return np.sum(np.abs(x1 - x2)**p)**(1/p)\n",
        "\n",
        "def knn_cross_validate(X, y, k=5, k_neighbors=3, distance_metric='euclidean', weights='uniform', kernel=None, n_splits=10):\n",
        "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "    accuracies = []\n",
        "\n",
        "    for train_index, test_index in kf.split(X):\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "\n",
        "        knn = KNN(k=k_neighbors, distance_metric=distance_metric, weights=weights, kernel=kernel)\n",
        "        knn.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "        predictions = knn.predict(X_test)\n",
        "\n",
        "\n",
        "        accuracy = np.sum(predictions == y_test) / len(y_test)\n",
        "        accuracies.append(accuracy)\n",
        "\n",
        "    return np.mean(accuracies), accuracies\n",
        "\n",
        "def compare_with_sklearn(X, y, k_neighbors=3, n_splits=10):\n",
        "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "    our_accuracies = []\n",
        "    sklearn_accuracies = []\n",
        "\n",
        "    for train_index, test_index in kf.split(X):\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "\n",
        "        knn = KNN(k=k_neighbors)\n",
        "        knn.fit(X_train, y_train)\n",
        "        our_predictions = knn.predict(X_test)\n",
        "        our_accuracy = np.sum(our_predictions == y_test) / len(y_test)\n",
        "        our_accuracies.append(our_accuracy)\n",
        "\n",
        "\n",
        "        sklearn_knn = KNeighborsClassifier(n_neighbors=k_neighbors)\n",
        "        sklearn_knn.fit(X_train, y_train)\n",
        "        sklearn_predictions = sklearn_knn.predict(X_test)\n",
        "        sklearn_accuracy = accuracy_score(y_test, sklearn_predictions)\n",
        "        sklearn_accuracies.append(sklearn_accuracy)\n",
        "\n",
        "\n",
        "    t_stat, p_value = stats.ttest_rel(our_accuracies, sklearn_accuracies)\n",
        "\n",
        "    return our_accuracies, sklearn_accuracies, t_stat, p_value\n",
        "\n",
        "\n",
        "def preprocess_hayes_roth(df):\n",
        "\n",
        "    X = df.iloc[:, :-1].values\n",
        "    y = df.iloc[:, -1].values\n",
        "\n",
        "\n",
        "    le = LabelEncoder()\n",
        "    for i in range(X.shape[1]):\n",
        "        X[:, i] = le.fit_transform(X[:, i])\n",
        "\n",
        "    y = le.fit_transform(y)\n",
        "\n",
        "    return X, y\n",
        "\n",
        "def preprocess_car_evaluation(df):\n",
        "\n",
        "    X = df.iloc[:, :-1].values\n",
        "    y = df.iloc[:, -1].values\n",
        "\n",
        "\n",
        "    le = LabelEncoder()\n",
        "    for i in range(X.shape[1]):\n",
        "        X[:, i] = le.fit_transform(X[:, i])\n",
        "\n",
        "    y = le.fit_transform(y)\n",
        "\n",
        "    return X, y\n",
        "\n",
        "def preprocess_breast_cancer(df):\n",
        "\n",
        "\n",
        "    df = df.drop(df.columns[0], axis=1)\n",
        "\n",
        "\n",
        "    X = df.iloc[:, 1:-1].values\n",
        "    y = df.iloc[:, -1].values\n",
        "\n",
        "\n",
        "    y = np.where(y == 'M', 1, 0)\n",
        "\n",
        "\n",
        "    X = np.where(X == '?', np.nan, X).astype(float)\n",
        "    col_means = np.nanmean(X, axis=0)\n",
        "    inds = np.where(np.isnan(X))\n",
        "    X[inds] = np.take(col_means, inds[1])\n",
        "\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X = scaler.fit_transform(X)\n",
        "\n",
        "    return X, y\n",
        "\n",
        "\n",
        "def download_file(url, filename):\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "    with open(filename, 'wb') as f:\n",
        "        f.write(response.content)\n",
        "\n",
        "\n",
        "    if not os.path.exists('hayes-roth.data'):\n",
        "        print(\"Downloading hayes-roth.data...\")\n",
        "        download_file(hayes_roth_url, 'hayes-roth.data')\n",
        "    if not os.path.exists('car.data'):\n",
        "        print(\"Downloading car.data...\")\n",
        "        download_file(car_url, 'car.data')\n",
        "    if not os.path.exists('wdbc.data'):\n",
        "        print(\"Downloading wdbc.data...\")\n",
        "        download_file(bc_url, 'wdbc.data')\n",
        "\n",
        "\n",
        "\n",
        "    hayes_roth_columns = ['name', 'hobby', 'age', 'educational level', 'marital status', 'class']\n",
        "    hayes_roth_df = pd.read_csv('hayes-roth.data', names=hayes_roth_columns)\n",
        "    X_hr, y_hr = preprocess_hayes_roth(hayes_roth_df)\n",
        "\n",
        "\n",
        "    car_columns = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'class']\n",
        "    car_df = pd.read_csv('car.data', names=car_columns)\n",
        "    X_car, y_car = preprocess_car_evaluation(car_df)\n",
        "\n",
        "\n",
        "    bc_columns = ['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean',\n",
        "                 'smoothness_mean', 'compactness_mean', 'concavity_mean', 'concave points_mean',\n",
        "                 'symmetry_mean', 'fractal_dimension_mean', 'radius_se', 'texture_se', 'perimeter_se',\n",
        "                 'area_se', 'smoothness_se', 'compactness_se', 'concavity_se', 'concave points_se',\n",
        "                 'symmetry_se', 'fractal_dimension_se', 'radius_worst', 'texture_worst', 'perimeter_worst',\n",
        "                 'area_worst', 'smoothness_worst', 'compactness_worst', 'concavity_worst',\n",
        "                 'concave points_worst', 'symmetry_worst', 'fractal_dimension_worst']\n",
        "    bc_df = pd.read_csv('wdbc.data', names=bc_columns)\n",
        "    X_bc, y_bc = preprocess_breast_cancer(bc_df)\n",
        "\n",
        "    return {\n",
        "        'Hayes-Roth': (X_hr, y_hr),\n",
        "        'Car Evaluation': (X_car, y_car),\n",
        "        'Breast Cancer': (X_bc, y_bc)\n",
        "    }\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    datasets = load_and_process_datasets()\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for name, (X, y) in datasets.items():\n",
        "        print(f\"Processing {name} dataset...\")\n",
        "\n",
        "\n",
        "        our_acc, sklearn_acc, t_stat, p_value = compare_with_sklearn(X, y, k_neighbors=5)\n",
        "\n",
        "\n",
        "        results[name] = {\n",
        "            'our_mean_accuracy': np.mean(our_acc),\n",
        "            'sklearn_mean_accuracy': np.mean(sklearn_acc),\n",
        "            't_statistic': t_stat,\n",
        "            'p_value': p_value,\n",
        "            'our_accuracies': our_acc,\n",
        "            'sklearn_accuracies': sklearn_acc\n",
        "        }\n",
        "\n",
        "        print(f\"{name} - Our KNN: {np.mean(our_acc):.4f}, Sklearn KNN: {np.mean(sklearn_acc):.4f}\")\n",
        "        print(f\"T-statistic: {t_stat:.4f}, P-value: {p_value:.4f}\")\n",
        "        print(\"=\"*50)\n",
        "\n",
        "\n",
        "    enhanced_results = {}\n",
        "\n",
        "    for name, (X, y) in datasets.items():\n",
        "        print(f\"Testing enhanced KNN on {name} dataset...\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        enhanced_accuracies = []\n",
        "        for config in configs:\n",
        "            mean_acc, accuracies = knn_cross_validate(\n",
        "                X, y,\n",
        "                k=config['k'],\n",
        "                k_neighbors=config['k'],\n",
        "                distance_metric=config['distance_metric'],\n",
        "                weights=config['weights'],\n",
        "                kernel=config['kernel']\n",
        "            )\n",
        "            enhanced_accuracies.append((config, mean_acc))\n",
        "            print(f\"Config: {config} -> Accuracy: {mean_acc:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "        enhanced_results[name] = enhanced_accuracies\n",
        "        print(\"=\"*50)"
      ]
    }
  ]
}